# Hadoop Map Reduce

*Description*: The goal of this programming assignment is two enable you to gain experience programming with:
- Amazon Web Services, specifically the EC2 cloud and S3
- the Hadoop open source framework, and
- break down a task into a parallel distributed MapReduce model

***

#### Setup

1. Sign up for an AWS account.
2. Find a dataset. The programming assignment involves manipulating/analyzing some large data set using cloud resources. 100 - 200 MB should be sufficient.
3. Install Hadoop on the Amazon instance AMI and process a large data set using the Hadop framework on EC2. Hadoop will have to be installed on VM instances.
4. Calculate the most frequent data item in your chosen data set.
***

#### Pseudocode

1. 

***

#### Files

- FTQueue.ipynb: Jupyter Notebook containing Python code for the FTQueue data structure program

- ECEN5673DianaSouthardHW2.pdf: Final report describing implemenation and current status of the data structure

***

#### Current Status

Nothing has been done yet, Raft is still being researched